import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'package:flutter/material.dart';
import 'package:flutter_sound/flutter_sound.dart';
import 'package:permission_handler/permission_handler.dart';

import '../models/recording.dart';
import '../models/summary_item.dart';
import '../services/google_stt_service.dart';
import '../services/gpt_service.dart';
import '../widgets/permission_gate.dart';
import 'result_screen.dart';
import 'package:ffmpeg_kit_flutter_new/ffmpeg_kit.dart';

// === ğŸ”§ ì„¤ì • ìƒìˆ˜ (í™•ì¥ì ë° ì½”ë± ì „ì—­ ê´€ë¦¬ìš©) ===
const String audioExtension = 'aac'; // ë°”ê¾¸ë ¤ë©´ 'aac', 'mp3' ë“±ìœ¼ë¡œ
const Codec audioCodec = Codec.aacADTS; // ë°”ê¾¸ë ¤ë©´ Codec.aacADTS, Codec.mp3 ë“±ìœ¼ë¡œ

// STT encoding ë§¤í•‘ í•¨ìˆ˜
String getSttEncoding() {
  switch (audioExtension) {
    case 'wav':
      return 'LINEAR16';
    case 'mp3':
      return 'MP3';
    case 'flac':
      return 'FLAC';
    case 'aac':
      return 'ENCODING_UNSPECIFIED';
    default:
      return 'ENCODING_UNSPECIFIED';
  }
}

// ğŸ›ï¸ FFmpeg ë³€í™˜ í•¨ìˆ˜ ì¶”ê°€
Future<File> convertToWav(File inputFile) async {
  final dir = inputFile.parent.path;
  final fileNameWithoutExt = inputFile.uri.pathSegments.last.split('.').first;
  final wavPath = '$dir/${fileNameWithoutExt}_converted.wav';

  final command =
      '-y -i "${inputFile.path}" -ar 16000 -ac 1 -c:a pcm_s16le "$wavPath"';

  final session = await FFmpegKit.execute(command);
  final returnCode = await session.getReturnCode();

  if (returnCode?.isValueSuccess() == true) {
    debugPrint('âœ… FFmpeg ë³€í™˜ ì„±ê³µ: $wavPath');
    return File(wavPath);
  } else {
    debugPrint('âŒ FFmpeg ë³€í™˜ ì‹¤íŒ¨: ${await session.getAllLogsAsString()}');
    throw Exception('FFmpeg ë³€í™˜ ì‹¤íŒ¨');
  }
}

// ğŸ§© ì‚¬ìš© ì‹œì  ì˜ˆì‹œ (RecordScreen._processRecording ë‚´ë¶€)
// File wavFile = await convertToWav(file);
// final raw = await _sttService.transcribe(wavFile, getSttEncoding());

Future<bool> ensureManageStoragePermission() async {
  final status = await Permission.manageExternalStorage.status;

  if (status.isGranted) {
    debugPrint('âœ… ëª¨ë“  íŒŒì¼ ì ‘ê·¼ ê¶Œí•œì´ ì´ë¯¸ í—ˆìš©ë˜ì–´ ìˆìŠµë‹ˆë‹¤.');
    return true;
  } else {
    debugPrint('ğŸš© ëª¨ë“  íŒŒì¼ ì ‘ê·¼ ê¶Œí•œì„ ìš”ì²­í•©ë‹ˆë‹¤.');

    // ì´ë¯¸ ìš”ì²­ ì¤‘ì´ë©´ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë¯€ë¡œ status í™•ì¸ë§Œ í•˜ê³ , requestëŠ” í•˜ì§€ ì•ŠìŒ
    if (await Permission.manageExternalStorage.isPermanentlyDenied ||
        await Permission.manageExternalStorage.isDenied) {
      return false; // ê±°ë¶€ ìƒíƒœë©´ falseë§Œ ë°˜í™˜í•˜ê³  ìš”ì²­ì€ í•˜ì§€ ì•ŠìŒ
    }

    final result = await Permission.manageExternalStorage.request();
    debugPrint('âœ… ê¶Œí•œ ìš”ì²­ ê²°ê³¼: $result');
    return result.isGranted;
  }
}

class RecordScreen extends StatefulWidget {
  const RecordScreen({Key? key}) : super(key: key);

  @override
  RecordScreenState createState() => RecordScreenState();
}

class RecordScreenState extends State<RecordScreen> {
  final FlutterSoundRecorder _recorder = FlutterSoundRecorder();
  final GoogleSTTService _sttService = GoogleSTTService();
  final GPTService _gptService = GPTService();

  StreamSubscription? _recorderSub;
  Timer? _timer;
  int _elapsedMs = 0;
  bool _isRecording = false;
  bool _isLoading = false;
  bool _recorderReady = false;
  String? _filePath;

  @override
  void initState() {
    super.initState();
    WidgetsBinding.instance.addPostFrameCallback((_) async {
      await ensureManageStoragePermission();
      await _initRecorder();
    });
  }

  Future<void> _initRecorder() async {
    await _recorder.openRecorder();
    _recorder.setSubscriptionDuration(const Duration(milliseconds: 100));
    _recorderSub = _recorder.onProgress?.listen((event) {
      final ms = event.duration.inMilliseconds;
      debugPrint('ğŸ™ï¸ ë…¹ìŒ ì¤‘... ${ms}ms');
      if (mounted) setState(() => _elapsedMs = ms);
    });
    if (!mounted) return;
    setState(() => _recorderReady = true);
  }

  Future<void> _toggleRecording() async {
    /*
    if (_isLoading || !_recorderReady) return;

    final micGranted = await Permission.microphone.isGranted;
    final storageGranted = await Permission.manageExternalStorage.isGranted;

    if (!micGranted || !storageGranted) {
      ScaffoldMessenger.of(context).showSnackBar(
        const SnackBar(content: Text('ê¶Œí•œ í—ˆìš© í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”')),
      );
      return;
    }
    */

    // â¬‡ ì´í•˜ ê¸°ì¡´ ë¡œì§ ìœ ì§€
    if (_isRecording) {
      _timer?.cancel();
      final tempPath = await _recorder.stopRecorder();
      debugPrint('ğŸ›‘ Recorder stopped, saved to: $tempPath');
      debugPrint('ğŸ“ Duration: ${_elapsedMs / 1000}ì´ˆ');
      await Future.delayed(const Duration(milliseconds: 100));
      if (tempPath == null) return;
      final file = File(tempPath);
      if (!file.existsSync()) return;

      setState(() {
        _isRecording = false;
        _filePath = tempPath;
      });
      await _processRecording(file);
    } else {
      setState(() {
        _isRecording = true;
        _elapsedMs = 0;
        _filePath = null;
      });

      final dir = Directory('/storage/emulated/0/AI_Sleep');
      if (!dir.existsSync()) dir.createSync(recursive: true);
      final outPath =
          '${dir.path}/consult_${DateTime.now().millisecondsSinceEpoch}.$audioExtension';

      try {
        debugPrint('ğŸ™ï¸ ë…¹ìŒ ì‹œì‘: $outPath');
        await _recorder.startRecorder(
          toFile: outPath,
          codec: audioCodec,
          sampleRate: 16000,
          numChannels: 1,
        );
        debugPrint('âœ… Recorder started');
        debugPrint('ğŸ™ï¸ isRecording: ${await _recorder.isRecording}');
        _timer = Timer.periodic(const Duration(milliseconds: 100), (t) {
          if (!_isRecording) {
            t.cancel();
            return;
          }
          if (mounted) setState(() => _elapsedMs += 100);
        });
      } catch (e) {
        setState(() => _isRecording = false);
        ScaffoldMessenger.of(context)
            .showSnackBar(SnackBar(content: Text('ë…¹ìŒ ì‹¤íŒ¨: $e')));
      }
    }
  }

  Future<void> _processRecording(File file) async {
    // ğŸ”„ ë³€í™˜: mp3 â†’ wav
    final wavFile = await convertToWav(file);

// ğŸ§  ìŒì„± í…ìŠ¤íŠ¸ ë³€í™˜ ìš”ì²­ (ë³€í™˜ëœ .wav íŒŒì¼ ì‚¬ìš©)
    final raw = await _sttService.transcribe(wavFile, getSttEncoding());
    setState(() => _isLoading = true);
    try {
      debugPrint('ğŸ“¤ STT ì „ì†¡ íŒŒì¼: ${wavFile.path}');
      debugPrint('ğŸ“¦ íŒŒì¼ í¬ê¸°: ${wavFile.lengthSync()} bytes');

      // 1) STT
      //    final raw = await _sttService.transcribe(file, getSttEncoding());

      debugPrint('ğŸ“„ STT ê²°ê³¼: $raw');
      if (raw == null || raw.trim().isEmpty) throw Exception('ìŒì„± ì¸ì‹ ì‹¤íŒ¨');

      // 2) GPT ìš”ì•½
      debugPrint('ğŸ¤– GPT ìš”ì•½ ìš”ì²­ ì‹œì‘...');
      final summaryText = await _gptService.summarizeText(raw);
      debugPrint('ğŸ“ GPT ìš”ì•½ ê²°ê³¼:\n$summaryText');
      if (summaryText == null || summaryText.isEmpty) {
        throw Exception('GPT ìš”ì•½ ì‹¤íŒ¨');
      }

      final lines = summaryText
          .split('\n')
          .map((l) => l.trim())
          .where((l) => l.isNotEmpty)
          .toList();

      final icons = lines
          .map((l) => RegExp(r'\[(.*?)\]').firstMatch(l)?.group(1) ?? '')
          .toList();

      final summaryItems = List<SummaryItem>.generate(
        lines.length,
        (i) => SummaryItem(
          iconCode: icons[i],
          text: lines[i].replaceAll(RegExp(r'\[.*?\]\s*'), ''),
        ),
      );

      // 3) í™˜ìëª… ì¶”ì¶œ
      debugPrint('ğŸ” í™˜ìëª… ì¶”ì¶œ ìš”ì²­...');
      final nameRaw = await _gptService.extractPatientName(raw);
      final patientName =
          (nameRaw?.replaceAll(RegExp(r'[^ê°€-í£a-zA-Z0-9]'), '_').trim()) ??
              'unknown';
      debugPrint('ğŸ§‘â€âš•ï¸ ì¶”ì¶œëœ í™˜ìëª…: $patientName');

      // 4) íŒŒì¼ ì´ë™ & ë©”íƒ€ ì €ì¥
      final dir = Directory('/storage/emulated/0/AI_Sleep');
      final base =
          'consult_${patientName}_${DateTime.now().millisecondsSinceEpoch}.$audioExtension';
      final audioPath = '${dir.path}/$base';
      final metaPath = '${dir.path}/$base.json';
      await file.rename(audioPath);
      debugPrint('ğŸ“ íŒŒì¼ ì €ì¥ ì™„ë£Œ: $audioPath');

      final rec = Recording(
        audioPath: audioPath,
        originalText: raw,
        summaryItems: summaryItems,
        createdAt: DateTime.now(),
        patientName: patientName,
      );
      await File(metaPath).writeAsString(
        jsonEncode(rec.toJson()),
        encoding: utf8,
      );
      debugPrint('ğŸ—ƒï¸ ë©”íƒ€ ì •ë³´ ì €ì¥ ì™„ë£Œ: $metaPath');

      if (!mounted) return;
      Navigator.pushReplacement(
        context,
        MaterialPageRoute(builder: (_) => ResultScreen(initialRecording: rec)),
      );
    } catch (e, stack) {
      debugPrint('ğŸ§¨ ì˜ˆì™¸ ë°œìƒ: $e');
      debugPrint(stack.toString());
      ScaffoldMessenger.of(context)
          .showSnackBar(SnackBar(content: Text('ì˜¤ë¥˜: $e')));
    } finally {
      if (mounted) setState(() => _isLoading = false);
    }
  }

  @override
  void dispose() {
    _recorderSub?.cancel();
    _timer?.cancel();
    _recorder.closeRecorder();
    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    return PermissionGate(
      requireMicrophone: true,
      requireStorage: true,
      child: Scaffold(
        appBar: AppBar(title: const Text('ìƒë‹´ ë…¹ìŒ')),
        body: Center(
          child: Column(
            mainAxisAlignment: MainAxisAlignment.center,
            children: [
              Icon(
                _isRecording ? Icons.mic : Icons.mic_none,
                size: 80,
                color: _isRecording ? Colors.red : Colors.grey,
              ),
              const SizedBox(height: 12),
              Text('ë…¹ìŒ ì‹œê°„: ${(_elapsedMs / 1000).toStringAsFixed(1)}ì´ˆ'),
              const SizedBox(height: 20),
              ElevatedButton(
                onPressed:
                    (_isLoading || !_recorderReady) ? null : _toggleRecording,
                child: _isLoading
                    ? const SizedBox(
                        width: 24,
                        height: 24,
                        child: CircularProgressIndicator(color: Colors.white),
                      )
                    : Text(_isRecording ? 'ë…¹ìŒ ì¤‘ì§€' : 'ë…¹ìŒ ì‹œì‘'),
              ),
              if (_filePath != null) ...[
                const SizedBox(height: 12),
                Text('íŒŒì¼ ì €ì¥: $_filePath', textAlign: TextAlign.center),
              ],
            ],
          ),
        ),
      ),
    );
  }
}
